{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e99207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c1e2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kakao크롤링 시작\n",
      "\n",
      "1페이지완료  2페이지완료  3페이지완료  4페이지완료  5페이지완료  6페이지완료  7페이지완료  8페이지완료  9페이지완료  10페이지완료  11페이지완료  12페이지완료  13페이지완료  14페이지완료  15페이지완료  16페이지완료  17페이지완료  18페이지완료  19페이지완료  20페이지완료  21페이지완료  22페이지완료  23페이지완료  24페이지완료  25페이지완료  26페이지완료  27페이지완료  28페이지완료  29페이지완료  30페이지완료  31페이지완료  32페이지완료  33페이지완료  34페이지완료  35페이지완료  36페이지완료  37페이지완료  38페이지완료  39페이지완료  40페이지완료  41페이지완료  42페이지완료  43페이지완료  44페이지완료  \n",
      "\n",
      "kakao크롤링 완료\n",
      "\n",
      "naver크롤링 시작\n",
      "\n",
      "1페이지완료  2페이지완료  3페이지완료  4페이지완료  5페이지완료  6페이지완료  7페이지완료  8페이지완료  9페이지완료  10페이지완료  11페이지완료  12페이지완료  13페이지완료  14페이지완료  15페이지완료  16페이지완료  17페이지완료  18페이지완료  19페이지완료  20페이지완료  21페이지완료  22페이지완료  23페이지완료  24페이지완료  25페이지완료  26페이지완료  27페이지완료  28페이지완료  29페이지완료  30페이지완료  31페이지완료  32페이지완료  33페이지완료  34페이지완료  35페이지완료  36페이지완료  37페이지완료  38페이지완료  39페이지완료  40페이지완료  41페이지완료  42페이지완료  43페이지완료  44페이지완료  \n",
      "\n",
      "naver크롤링 완료\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 크롬으로 웹창 시작  # 한번에 4개 csv 파일 만들 수 있도록 정리 요망\n",
    "browser = webdriver.Chrome()\n",
    "# 증권 데이터 url 정의  (삼성=005930, SK하이닉스=000660, SK스퀘어=402340, DB하이텍=000990)\n",
    "\n",
    "# 받을 데이터 추가\n",
    "datas_1 = [['samsung', '005930'],['skhynix', '000660'], ['sksquare', '402340'], ['dbhitek', '000990']]\n",
    "datas_2 = [['kakao', '035720'], ['naver', '035420']]\n",
    "\n",
    "# 날짜 지정  예시) 2020.01.01\n",
    "start_date = '2021.07.01'\n",
    "end_date = '2022.12.31'\n",
    "\n",
    "for com_name, com_code in datas_2:\n",
    "    page = 1\n",
    "    print(f'{com_name}크롤링 시작\\n')\n",
    "    # 페이지 변수 p도 날짜에 맞춰서 정해줘야 한다.\n",
    "    for p in range(1, 45):\n",
    "        url = f'https://finance.naver.com/item/sise_day.naver?code={com_code}&page={page}'\n",
    "        # url 정보 가져오기\n",
    "        browser.get(url)\n",
    "        # 삼성 데이터 추출\n",
    "        com_df = pd.read_html(browser.page_source)[0]\n",
    "        ## 전처리\n",
    "        # 모든 행의 요소가 결측치일 경우 행 삭제\n",
    "        com_df.dropna(axis='index', how='all', inplace=True)\n",
    "        # 전일비 culumn 삭제\n",
    "        com_df.drop(['전일비'], axis=1, inplace=True)\n",
    "        # 날짜 조정\n",
    "        com_df = com_df[(com_df.날짜 >= start_date) & (com_df.날짜 <= end_date)]        \n",
    "        # csv파일로 저장\n",
    "        com_info = f'./csvs/{com_name}.csv'\n",
    "        if os.path.exists(com_info):\n",
    "            com_df.to_csv(com_info, encoding='utf-8-sig', index=False, mode='a', header=False)\n",
    "        else:\n",
    "            com_df.to_csv(com_info, encoding='utf-8-sig', index=False)\n",
    "        print(f'{page}페이지완료', end='  ')\n",
    "        page += 1\n",
    "    print(f'\\n\\n{com_name}크롤링 완료\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e28ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
