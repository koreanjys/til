{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2185d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2439300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 당뇨병 데이터 불러오기\n",
    "df = pd.read_csv('diabetes_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b584f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature와 target 분리\n",
    "target = df[['Diabetes']]\n",
    "data = df.drop(columns=['Diabetes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026560aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81677be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline 을 위한 전처리 모듈 불러오기\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8adb730d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HighBP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50498</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44300</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49497</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Sex  HighChol  CholCheck   BMI  Smoker  HeartDiseaseorAttack  \\\n",
       "50498  13.0  0.0       1.0        1.0  32.0     1.0                   1.0   \n",
       "44300  10.0  0.0       1.0        1.0  22.0     0.0                   0.0   \n",
       "49497   8.0  1.0       1.0        1.0  35.0     0.0                   0.0   \n",
       "\n",
       "       PhysActivity  Fruits  Veggies  HvyAlcoholConsump  GenHlth  MentHlth  \\\n",
       "50498           1.0     1.0      1.0                0.0      3.0       0.0   \n",
       "44300           1.0     0.0      0.0                0.0      4.0      10.0   \n",
       "49497           0.0     1.0      0.0                0.0      3.0       5.0   \n",
       "\n",
       "       PhysHlth  DiffWalk  Stroke  HighBP  \n",
       "50498       0.0       0.0     0.0     1.0  \n",
       "44300      20.0       0.0     0.0     1.0  \n",
       "49497       0.0       0.0     0.0     1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3939e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인\n",
    "# 수로 된 열 선택\n",
    "numeric_features = ['Age', 'BMI', 'MentHlth', 'PhysHlth']\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# 수로 된 열 제외한 모든 라벨로 된 열 선택\n",
    "categorical_features = list(x_train.columns)\n",
    "categorical_features.remove('Age')\n",
    "categorical_features.remove('BMI')\n",
    "categorical_features.remove('MentHlth')\n",
    "categorical_features.remove('PhysHlth')\n",
    "\n",
    "categorical_transformer = OneHotEncoder(categories='auto', handle_unknown='ignore') \n",
    "\n",
    "# 전처리 모델 생성\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da76894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인으로 전처리\n",
    "preprocessor_pipe = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a35314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['Age', 'BMI', 'MentHlth',\n",
       "                                                   'PhysHlth']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['Sex', 'HighChol',\n",
       "                                                   'CholCheck', 'Smoker',\n",
       "                                                   'HeartDiseaseorAttack',\n",
       "                                                   'PhysActivity', 'Fruits',\n",
       "                                                   'Veggies',\n",
       "                                                   'HvyAlcoholConsump',\n",
       "                                                   'GenHlth', 'DiffWalk',\n",
       "                                                   'Stroke', 'HighBP'])]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이프라인 학습\n",
    "preprocessor_pipe.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dab32b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 학습된 전처리로 변환\n",
    "x_train = preprocessor_pipe.transform(x_train)\n",
    "x_test = preprocessor_pipe.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c4b1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 모듈 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, utils\n",
    "from tensorflow.keras import models, layers, activations, initializers, losses, optimizers, metrics\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3056900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 데이터 원핫인코딩\n",
    "# y_train = utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3a2986e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56553, 33)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7733457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Build the hyper-model\n",
    "# Available HyperParameter search spaces (https://j.mp/2IXPzh7) : Int, Float, Boolean, Choice, Fixed\n",
    "\n",
    "def build_hyper_model(hp):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(input_dim=33, units=64)) # change 2-dims MNIST dataset to 1-dim \n",
    "        \n",
    "    # Tune the number of hidden layer (Choose an optimal value between 1~3)\n",
    "    for layer_num in range(hp.Int('num_layers', min_value=1, max_value=3)): \n",
    "        # Tune the number of perceptrons in a dense layer (Choose an optimal value between 32~512) \n",
    "        hp_units = hp.Int('units_' + str(layer_num), min_value=32, max_value=512, step=32) # 32:512 & step 32, all parameter names should be unique (we name the inner parameters 'units_' + str(i))\n",
    "        hp_activations = hp.Choice('activation_' + str(layer_num), values=['relu', 'elu'])\n",
    "        model.add(layers.Dense(units = hp_units, activation = hp_activations))\n",
    "\n",
    "    model.add(layers.Dense(units=1, activation='sigmoid')) # class 10 : 0~9\n",
    "\n",
    "    # Tune the learning rate for the optimizer (Choose an optimal value from 0.01, 0.001, or 0.0001)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "    \n",
    "    model.compile(optimizer = optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss = losses.binary_crossentropy, # use sparse c.c when our labels are looks like \"1\" (single integer), not \"[1,0,0]\" (one-hot vector) (@ http://j.mp/2XS0jmv)\n",
    "                metrics = [metrics.binary_accuracy])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e9937bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from test_prac_dir\\diabetes_hyper_1\\tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 8\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation_1 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu'], 'ordered': False}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation_2 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "# 3) Select tuner and compile it\n",
    "# Available tuners (https://j.mp/39cWz4n) : kt.BayesianOptimization / kt.Hyperband / kt.RandomSearch / kt.Sklearn (https://j.mp/3nSJn8O)\n",
    "\n",
    "tuner = kt.BayesianOptimization(build_hyper_model,\n",
    "                                objective = 'val_accuracy', # Hyper-params tuning을 위한 목적함수 설정 (metric to minimize or maximize)\n",
    "                                max_trials = 10, # 서로 다른 Hyper-params 조합으로 시도할 총 Trial 횟수 설정\n",
    "                                directory = 'test_prac_dir', # Path to the working directory\n",
    "                                project_name = 'diabetes_hyper_1') # Name to use as directory name for files saved by this Tuner\n",
    "\n",
    "# tuner = kt.Hyperband(build_hyper_model,\n",
    "#                      objective = 'val_accuracy', # Hyper-params tuning을 위한 목적함수 설정 (metric to minimize or maximize)\n",
    "#                      max_epochs = 5, # 최대 epoch 수 설정, epoch 수 자체도 지정한 최대 횟수 내에서 변화시켜가며 테스트를 진행함 (epochs to train one model) \n",
    "#                      directory = 'test_prac_dir', # Path to the working directory\n",
    "#                      project_name = 'MNIST_hyper_1') # Name to use as directory name for files saved by this Tuner\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86ec2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 12s]\n",
      "\n",
      "Best val_accuracy So Far: None\n",
      "Total elapsed time: 00h 01m 59s\n",
      "\n",
      "Search: Running Trial #6\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "2                 |2                 |num_layers\n",
      "448               |288               |units_0\n",
      "elu               |elu               |activation_0\n",
      "0.001             |0.01              |learning_rate\n",
      "128               |64                |units_1\n",
      "elu               |elu               |activation_1\n",
      "224               |192               |units_2\n",
      "relu              |relu              |activation_2\n",
      "\n",
      "Epoch 1/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5219 - binary_accuracy: 0.7435 - val_loss: 0.5194 - val_binary_accuracy: 0.7426\n",
      "Epoch 2/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5129 - binary_accuracy: 0.7467 - val_loss: 0.5148 - val_binary_accuracy: 0.7455\n",
      "Epoch 3/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5098 - binary_accuracy: 0.7482 - val_loss: 0.5085 - val_binary_accuracy: 0.7468\n",
      "Epoch 4/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5099 - binary_accuracy: 0.7495 - val_loss: 0.5110 - val_binary_accuracy: 0.7457\n",
      "Epoch 5/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5090 - binary_accuracy: 0.7504 - val_loss: 0.5121 - val_binary_accuracy: 0.7480\n",
      "Epoch 6/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5088 - binary_accuracy: 0.7513 - val_loss: 0.5137 - val_binary_accuracy: 0.7444\n",
      "Epoch 7/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5083 - binary_accuracy: 0.7500 - val_loss: 0.5127 - val_binary_accuracy: 0.7486\n",
      "Epoch 8/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5073 - binary_accuracy: 0.7509 - val_loss: 0.5083 - val_binary_accuracy: 0.7491\n",
      "Epoch 9/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5072 - binary_accuracy: 0.7507 - val_loss: 0.5105 - val_binary_accuracy: 0.7463\n",
      "Epoch 10/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5065 - binary_accuracy: 0.7521 - val_loss: 0.5126 - val_binary_accuracy: 0.7470\n",
      "Epoch 11/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5061 - binary_accuracy: 0.7515 - val_loss: 0.5084 - val_binary_accuracy: 0.7503\n",
      "Epoch 12/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5062 - binary_accuracy: 0.7520 - val_loss: 0.5109 - val_binary_accuracy: 0.7484\n",
      "Epoch 13/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5059 - binary_accuracy: 0.7538 - val_loss: 0.5146 - val_binary_accuracy: 0.7440\n",
      "Epoch 14/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5055 - binary_accuracy: 0.7535 - val_loss: 0.5071 - val_binary_accuracy: 0.7481\n",
      "Epoch 15/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5048 - binary_accuracy: 0.7517 - val_loss: 0.5111 - val_binary_accuracy: 0.7508\n",
      "Epoch 16/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5047 - binary_accuracy: 0.7532 - val_loss: 0.5077 - val_binary_accuracy: 0.7464\n",
      "Epoch 17/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5048 - binary_accuracy: 0.7537 - val_loss: 0.5107 - val_binary_accuracy: 0.7480\n",
      "Epoch 18/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5045 - binary_accuracy: 0.7535 - val_loss: 0.5103 - val_binary_accuracy: 0.7470\n",
      "Epoch 19/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5042 - binary_accuracy: 0.7536 - val_loss: 0.5127 - val_binary_accuracy: 0.7458\n",
      "Epoch 20/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5040 - binary_accuracy: 0.7531 - val_loss: 0.5078 - val_binary_accuracy: 0.7499\n",
      "Epoch 21/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5033 - binary_accuracy: 0.7536 - val_loss: 0.5140 - val_binary_accuracy: 0.7449\n",
      "Epoch 22/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5032 - binary_accuracy: 0.7544 - val_loss: 0.5102 - val_binary_accuracy: 0.7473\n",
      "Epoch 23/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5033 - binary_accuracy: 0.7535 - val_loss: 0.5133 - val_binary_accuracy: 0.7440\n",
      "Epoch 24/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5028 - binary_accuracy: 0.7555 - val_loss: 0.5126 - val_binary_accuracy: 0.7458\n",
      "Epoch 25/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5023 - binary_accuracy: 0.7541 - val_loss: 0.5197 - val_binary_accuracy: 0.7432\n",
      "Epoch 26/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5023 - binary_accuracy: 0.7533 - val_loss: 0.5100 - val_binary_accuracy: 0.7508\n",
      "Epoch 27/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5018 - binary_accuracy: 0.7563 - val_loss: 0.5135 - val_binary_accuracy: 0.7494\n",
      "Epoch 28/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5021 - binary_accuracy: 0.7548 - val_loss: 0.5090 - val_binary_accuracy: 0.7466\n",
      "Epoch 29/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5013 - binary_accuracy: 0.7549 - val_loss: 0.5081 - val_binary_accuracy: 0.7481\n",
      "Epoch 30/30\n",
      "1238/1238 [==============================] - 2s 2ms/step - loss: 0.5014 - binary_accuracy: 0.7542 - val_loss: 0.5097 - val_binary_accuracy: 0.7465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 261, in _run_and_update_trial\n",
      "    tuner_utils.convert_to_metrics_dict(\n",
      "  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner_utils.py\", line 225, in convert_to_metrics_dict\n",
      "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
      "  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner_utils.py\", line 225, in <listcomp>\n",
      "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
      "  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner_utils.py\", line 238, in convert_to_metrics_dict\n",
      "    best_value, _ = _get_best_value_and_best_epoch_from_history(\n",
      "  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner_utils.py\", line 209, in _get_best_value_and_best_epoch_from_history\n",
      "    objective_value = objective.get_value(metrics)\n",
      "  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\objective.py\", line 57, in get_value\n",
      "    return logs[self.name]\n",
      "KeyError: 'val_accuracy'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 261, in _run_and_update_trial\n    tuner_utils.convert_to_metrics_dict(\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner_utils.py\", line 225, in convert_to_metrics_dict\n    [convert_to_metrics_dict(elem, objective) for elem in results]\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner_utils.py\", line 225, in <listcomp>\n    [convert_to_metrics_dict(elem, objective) for elem in results]\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner_utils.py\", line 238, in convert_to_metrics_dict\n    best_value, _ = _get_best_value_and_best_epoch_from_history(\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner_utils.py\", line 209, in _get_best_value_and_best_epoch_from_history\n    objective_value = objective.get_value(metrics)\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\objective.py\", line 57, in get_value\n    return logs[self.name]\nKeyError: 'val_accuracy'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7208\\1070697652.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 4) Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# epochs == learning epoch for training a single model(epoch for each trial)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36mon_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \"\"\"\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[1;31m# Display needs the updated trial scored by the Oracle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\oracle.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mLOCKS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthread_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mret_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mneed_acquire\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\oracle.py\u001b[0m in \u001b[0;36mend_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_order\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_consecutive_failures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\oracle.py\u001b[0m in \u001b[0;36m_check_consecutive_failures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[0mconsecutive_failures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconsecutive_failures\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m                 raise RuntimeError(\n\u001b[0m\u001b[0;32m    387\u001b[0m                     \u001b[1;34m\"Number of consecutive failures excceeded the limit \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                     \u001b[1;34mf\"of {self.max_consecutive_failed_trials}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 261, in _run_and_update_trial\n    tuner_utils.convert_to_metrics_dict(\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner_utils.py\", line 225, in convert_to_metrics_dict\n    [convert_to_metrics_dict(elem, objective) for elem in results]\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner_utils.py\", line 225, in <listcomp>\n    [convert_to_metrics_dict(elem, objective) for elem in results]\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner_utils.py\", line 238, in convert_to_metrics_dict\n    best_value, _ = _get_best_value_and_best_epoch_from_history(\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner_utils.py\", line 209, in _get_best_value_and_best_epoch_from_history\n    objective_value = objective.get_value(metrics)\n  File \"C:\\Users\\TECH2_30\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\objective.py\", line 57, in get_value\n    return logs[self.name]\nKeyError: 'val_accuracy'\n"
     ]
    }
   ],
   "source": [
    "# 4) Train the model\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=30, validation_split=0.3) # epochs == learning epoch for training a single model(epoch for each trial) \n",
    "\n",
    "\n",
    "# # 아래와 같이 별도의 클래스로 콜백을 정의하여 search 함수에서 활용하면 모든 학습 단계 종료 후 학습 중 발생한 출력 결과를 자동으로 지워낼 수 있습니다.\n",
    "# class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "#   def on_train_end(*args, **kwargs):\n",
    "#     IPython.display.clear_output(wait = True)\n",
    "\n",
    "# tuner.search(x_train, y_train, epochs = 7, validation_data = (x_test, y_test), callbacks = [ClearTrainingOutput()]) # epochs == learning epoch for training a single model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7128d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Check the result \n",
    "\n",
    "tuner.results_summary(num_trials=3) # Show \"n\" best trial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check top-3 trials' hyper-params\n",
    "\n",
    "top3_models = tuner.get_best_hyperparameters(num_trials=3)\n",
    "# print(tuner.get_best_hyperparameters(num_trials=3)[0].space) # 특정 Trial의 Search-space 를 확인할 수 있음\n",
    "# print(tuner.get_best_hyperparameters(num_trials=3)[0].values) # 특정 Trial에 적용된 Hyper-params를 확인할 수 있음\n",
    "\n",
    "for idx, model in enumerate(top3_models):\n",
    "    print('Model performance rank :', idx)\n",
    "    print(model.values)\n",
    "    print()\n",
    "\n",
    "\n",
    "# Check the best trial's hyper-params\n",
    "\n",
    "best_hps = top3_models[0]\n",
    "\n",
    "print(\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "* Optimal # of layers : {}\n",
    "* Optimal value of the learning-rate : {}\"\"\".format(best_hps.get('num_layers'), best_hps.get('learning_rate')))\n",
    "\n",
    "for layer_num in range(best_hps.get('num_layers')):\n",
    "    print('Layer {} - # of Perceptrons :'.format(layer_num), best_hps.get('units_' + str(layer_num)))\n",
    "    print('Layer {} - Applied activation function :'.format(layer_num), best_hps.get('activation_' + str(layer_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd7b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from trials\n",
    "\n",
    "models = tuner.get_best_models(num_models=3) # Keras Sequential models\n",
    "top_model = models[0]\n",
    "top_model.summary()\n",
    "print()\n",
    "\n",
    "results = top_model.evaluate(x_test, y_test)\n",
    "print('Cross-entropy :', results[0])\n",
    "print('Accuracy :', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25107bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can retrain the model with the optimal hyperparameters from the search.\n",
    "best_hps = top3_models[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data.\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print('Cross-entropy :', results[0])\n",
    "print('Accuracy :', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also find detailed logs, checkpoints, etc, in the folder \"directory/project_name\".\n",
    "\n",
    "# The [test_prac_dir/MNIST_hyper_1] directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. \n",
    "# If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. \n",
    "# To disable this behavior, pass an additional [overwrite = True] argument while instantiating the tuner.\n",
    "\n",
    "for trial in tuner.oracle.get_best_trials(num_trials=3):\n",
    "    print('Trial-score is :', trial.score)\n",
    "    print('Trial-directory(trial_id) is :', trial.trial_id)\n",
    "    print()\n",
    "\n",
    "# tuner.oracle.trials -> get all trial_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e98d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
