# Preprocessor(전처리)
- 전처리는 매우 중요한데, 이유는 전처리를 해주는 것 만으로도 모델 성능이 매우 높게 나온다.
  
- Train 데이터만 전처리를 해주고 Test는 건들지 않는다.

## `Numerical(계산 가능한) 데이터 (회귀 분석)`
- Numerical Data의 전처리는 여러가지 종류가 있다.
  
1. MinMaxScaler

>> minmax값을 사용하여 전처리를 한다. 0 ~ 1 사이 값으로 변환

2. StandardScaler(성능이 좋음)
   
>> 표준편차 등을 이용하여 전처리. -1 ~ 1 사이 값으로 변환

## `Classification (분류 분석)`
- Classification의 전처리도 여러가지 종류가 있다.

1. LabelEncoder

>> 이걸 사용하면 예를들어 남자, 여자 두 class가 있으면 0과 1로 바꿔준다.

2. OneHotEncoder

>> 원-핫-인코딩을 사용하면 여러 class를 여러 컬럼으로 나누고 각 데이터가 속하는 칼럼에 1로 들어가고 속하지 않는 칼럼엔 0으로 표시되는 전처리 방법 


# RBF(가우시안) 커널 SVM(SupportVectorMachine)을 유방암 데이터셋에 적용해보기

## `1. 데이터 준비 및 데이터 키 값 확인`
```
from sklearn.datasets import load_breast_cancer

data = load_breast_cancer()
# data.keys()  # 키 값 확인
# data['data'].shape
# data['target'].shape
# print(data['DESCR'])
# data['target_names']
```
## `2. SVM모델을 불러오고 => Train Test 분류하고 => SVM 학습하여 => score 확인`
```
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

cancer = load_breast_cancer()

X_train, X_test, y_train, y_test = train_test_split(
    cancer.data, cancer.target, random_state=0) # stratify=cancer.target : 각 class 비율을 train & test split 시 유지

# gamma를 default 값인'scale'로 적용하면 자동으로 문제가 해결되나(auto-scaling) 직접 문제를 발견하고 해결하기 위해 'auto'로 적용합니다.
svc = SVC(gamma='auto') 
svc.fit(X_train, y_train)

print("Accuracy on Training set: {:.3f}".format(svc.score(X_train, y_train)))
print("Accuracy on Test set: {:.3f}".format(svc.score(X_test, y_test)))
```
과대적합이 발생했다.(gamma 값을 'scale'로 주면 문제가 해결되지만, 일부러 과대적합 발생시키기 위해 'auto'로 적용)

score는 Train 1로 과대적합, Test 0.629...으로 형편없는 예측률.

이는 모델 문제가 아니고 데이터 문제이므로 전처리 진행 

## `3. 데이터 전처리`

- Numerical 컬럼의 경우 StandardScaler 를 사용
- Classification 칼럼의 경우 OneHotEncoder 사용

<br>

현재 데이터의 경우 각 컬럼의 수치 범위(scale)이 적게는 0.01부터 크게는 1000이상 까지 제각각이다. 이 경우 Kernelized SVM 에서는 영향이 아주 크다. 모든 컬럼이 Numerical 컬럼이기 때문에 전부 StandardScaler 사용


데이터의 범위를 0~1 사이로 맞추는 Min-maxNormalization(정규화) 대신, 평균이 0 & 표준편차가 1 이 되게끔 Standardization(표준화)를 적용할 수도 있습니다.

이 때는 sklearn.preprocessing.StandardScaler 를 간편하게 활용할 수 있습니다.


### 1. standard scaler 불러오기
```
from sklearn.preprocessing import StandardScaler
```
<br>

### 2. X_train의 평균과 표준편차를 구한다. (X_test는 아직 자료가 없다고 생각하고 건들지 않는다.)

```
sc = StandardScaler()
sc.fit(X_train) # X_train 의 평균과 표준편차를 구함
```
<br>

### 3. X_train과 X_test의 Scaler 적용
```
X_train_scaled = sc.transform(X_train)
X_test_scaled = sc.transform(X_test)
```
위와 같이 적용하면 기존 자료에 Scaler한 값으로 덮어쓴다. (값 범위는 -1 ~ 1로 분포)

<br>

### 4. Scaled 된 데이터를 학습 시키기
```
# from sklearn.svm import SVC

svc = SVC(gamma='auto')
svc.fit(X_train_scaled, y_train)
```
<br>

### 5. score 확인
```
print("Accuracy on Training set: {:.3f}".format(svc.score(X_train_scaled, y_train)))
print("Accuracy on Test set: {:.3f}".format(svc.score(X_test_scaled, y_test)))

<결과>
Accuracy on Training set: 0.986
Accuracy on Test set: 0.965
```
<br>

여기서 C 값이나 gamma 값을 증가시켜 더 복잡한 모델을 만들 수 있다.
```
 C나 gamma 값을 증가시켜 좀 더 복잡한 모델을 만들 수 있음

svc = SVC(C=1000, gamma=0.1)
svc.fit(X_train_scaled, y_train)

print("Accuracy on Training set: {:.3f}".format(svc.score(X_train_scaled, y_train)))
print("Accuracy on Test set: {:.3f}".format(svc.score(X_test_scaled, y_test)))

<결과>
Accuracy on Training set: 1.000
Accuracy on Test set: 0.965
```
과대적합 같으나, 예측률이 매우 높게 나온다.

<br>

### 6. 최적의 C값과 gamma값을 찾아주는(최적의 Hyper Parameter 를 찾아주는) GridSearch

- GridSearch 보다는 Bayesian 이 더 좋다. 다만 여기선 GridSearch를 사용해본다.

```
from sklearn.model_selection import GridSearchCV

# 아래 param_grid dict 의 C & gamma 에 후보 Hyper-params 값들을 리스트업합니다.
param_grid = {'C' : [0.1, 1, 10, 100, 1000], 
             'gamma' : [1, 0.1, 0.01, 0.001, 0.0001],
             'kernel' : ['rbf']}

grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=1)
# refit : 찾아진 가장 좋은 params로 estimator를 setting할 지 여부 (setting해줘야 곧바로 predict가 가능)
# verbose : 설명의 자세한 정도 (verbose를 3과 같이 바꿔보시면 더 자세하게 매 param set 마다의 결과를 확인할 수 있습니다.)

grid.fit(X_train_scaled, y_train)
print('The best parameters are ', grid.best_params_)

<결과>
Fitting 5 folds for each of 25 candidates, totalling 125 fits
The best parameters are  {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}
```
<br>

```
from sklearn.metrics import classification_report

grid_predictions = grid.predict(X_test_scaled)
print(classification_report(y_test, grid_predictions)) # Precision, Recall, F1-score 등을 확인할 수 있습니다.

print("Accuracy on Training set: {:.3f}".format(grid.score(X_train_scaled, y_train)))
print("Accuracy on Test set: {:.3f}".format(grid.score(X_test_scaled, y_test)))
```